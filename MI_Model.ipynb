{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"},{"sourceId":454442,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":368749,"modelId":389625}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.signal import butter, lfilter, iirnotch, filtfilt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\nimport joblib","metadata":{"_uuid":"03f5ee73-1537-43ce-9837-aeba9516125f","_cell_guid":"a28ca966-ae29-4961-8f96-2951cbba72c3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:31.618228Z","iopub.execute_input":"2025-06-30T17:14:31.619015Z","iopub.status.idle":"2025-06-30T17:14:36.406463Z","shell.execute_reply.started":"2025-06-30T17:14:31.618974Z","shell.execute_reply":"2025-06-30T17:14:36.405721Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"c5a5d4fb-61d7-436c-80ef-79a43f93ff73","_cell_guid":"f13e3703-75d4-4b0f-8d51-5f894abf9fd1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:36.407719Z","iopub.execute_input":"2025-06-30T17:14:36.408117Z","iopub.status.idle":"2025-06-30T17:14:38.489697Z","shell.execute_reply.started":"2025-06-30T17:14:36.408094Z","shell.execute_reply":"2025-06-30T17:14:38.488908Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mtcaic3/sample_submission.csv\n/kaggle/input/mtcaic3/README.md\n/kaggle/input/mtcaic3/validation.csv\n/kaggle/input/mtcaic3/train.csv\n/kaggle/input/mtcaic3/test.csv\n/kaggle/input/mtcaic3/SSVEP/validation/S32/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/validation/S33/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/validation/S31/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/validation/S35/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/validation/S34/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/test/S39/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/test/S40/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/test/S37/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/test/S38/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/test/S36/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S26/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S20/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S18/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S25/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S24/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S14/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S27/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S1/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S11/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S13/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S19/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S29/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S10/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S8/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S5/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S7/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S28/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S9/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S15/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S21/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S2/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S6/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S30/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S3/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S23/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S4/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S16/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S17/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S22/6/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/7/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/2/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/5/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/8/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/3/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/1/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/4/EEGdata.csv\n/kaggle/input/mtcaic3/SSVEP/train/S12/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/validation/S32/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/validation/S33/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/validation/S31/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/validation/S35/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/validation/S34/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/test/S39/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/test/S40/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/test/S37/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/test/S38/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/test/S36/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S26/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S20/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S18/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S25/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S24/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S14/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S27/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S1/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S11/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S13/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S19/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S29/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S10/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S8/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S5/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S7/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S28/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S9/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S15/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S21/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S2/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S6/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S30/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S3/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S23/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S4/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S16/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S17/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S22/6/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/7/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/2/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/5/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/8/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/3/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/1/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/4/EEGdata.csv\n/kaggle/input/mtcaic3/MI/train/S12/6/EEGdata.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def butter_bandpass(lowcut, highcut, fs, order=4):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\ndef notch_filter(data, fs=250, freq=50.0, Q=30.0):\n    b, a = iirnotch(freq / (0.5 * fs), Q)\n    return filtfilt(b, a, data, axis=0)\n\ndef bandpass_filter(data, lowcut=7, highcut=30, fs=250):\n    b, a = butter_bandpass(lowcut, highcut, fs)\n    data = lfilter(b, a, data, axis=0)\n    return notch_filter(data, fs=fs)\ndef add_noise(eeg, noise_std=0.01):\n    noise = np.random.normal(0, noise_std, eeg.shape)\n    return eeg + noise\n\ndef normalize_per_trial(eeg):\n    mean = np.mean(eeg, axis=1, keepdims=True)\n    std = np.std(eeg, axis=1, keepdims=True) + 1e-6\n    return (eeg - mean) / std\n\ndef standardize_global(eeg, mean, std):\n    return (eeg - mean) / (std + 1e-6)\n   \ndef mixup_data(x, y, alpha=0.4):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam","metadata":{"_uuid":"d08acdf4-7c38-4fa5-b9d1-8da6c7ca5ee2","_cell_guid":"ba1a6ca4-4783-4ca3-a4a7-bbe4a95d436b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:38.490435Z","iopub.execute_input":"2025-06-30T17:14:38.490610Z","iopub.status.idle":"2025-06-30T17:14:38.499573Z","shell.execute_reply.started":"2025-06-30T17:14:38.490597Z","shell.execute_reply":"2025-06-30T17:14:38.498658Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class EEGDataset(Dataset):\n    def __init__(self, task, split, base_path='./kaggle/input/mtcaic3', apply_noise=True, apply_trial_norm=True, apply_global_std=False, global_mean=None, global_std=None):\n        self.task = task\n        self.split = split\n        self.base_path = base_path\n        self.apply_noise = apply_noise\n        self.apply_trial_norm = apply_trial_norm\n        self.apply_global_std = apply_global_std\n        self.global_mean = global_mean\n        self.global_std = global_std\n\n        self.meta_df = pd.read_csv(os.path.join(base_path, f'{split}.csv'))\n        self.meta_df = self.meta_df[self.meta_df['task'] == task]\n\n        self.label_encoder = LabelEncoder()\n        if split != 'test':\n            self.meta_df['label_enc'] = self.label_encoder.fit_transform(self.meta_df['label'])\n\n    def __len__(self):\n        return len(self.meta_df)\n\n    def __getitem__(self, idx):\n        row = self.meta_df.iloc[idx]\n        eeg_path = os.path.join(\n            self.base_path,\n            row['task'],\n            self.split,\n            row['subject_id'],\n            str(row['trial_session']),\n            'EEGdata.csv'\n        )\n\n        df = pd.read_csv(eeg_path)\n\n        samples_per_trial = 2250 if row['task'] == 'MI' else 1750\n        trial_num = int(row['trial'])\n        start_idx = (trial_num - 1) * samples_per_trial\n        end_idx = start_idx + samples_per_trial\n\n        df = df.iloc[start_idx:end_idx]\n        eeg = df[['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']].values\n        #eeg = df[['C3', 'CZ', 'C4']].values\n\n        eeg = bandpass_filter(eeg)\n\n        # Apply per-trial z-score normalization\n        if self.apply_trial_norm:\n            eeg = normalize_per_trial(eeg)\n\n        # Apply global standardization\n        if self.apply_global_std and self.global_mean is not None and self.global_std is not None:\n            eeg = standardize_global(eeg, self.global_mean, self.global_std)\n\n        # Apply Gaussian noise\n        if self.apply_noise and self.split == 'train':\n            eeg = add_noise(eeg)\n\n        eeg = eeg.T  # Shape: (channels, time)\n        eeg = torch.tensor(eeg.copy(), dtype=torch.float32)  # .copy() to avoid negative strides\n\n        if self.split != 'test':\n            label = torch.tensor(row['label_enc'], dtype=torch.long)\n            return eeg, label\n        else:\n            return eeg","metadata":{"_uuid":"5c428779-c7e3-4d9b-b537-87a7cff0b6ac","_cell_guid":"4221c72c-7c5c-4a5e-92c3-3556667287a8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:38.500896Z","iopub.execute_input":"2025-06-30T17:14:38.501077Z","iopub.status.idle":"2025-06-30T17:14:38.519964Z","shell.execute_reply.started":"2025-06-30T17:14:38.501062Z","shell.execute_reply":"2025-06-30T17:14:38.519344Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\n# --- Positional Encoding ---\nclass PositionalEncoding(nn.Module):\n    def __init__(self, dim, max_len=500):\n        super(PositionalEncoding, self).__init__()\n        pe = torch.zeros(max_len, dim)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # Shape: [1, max_len, dim]\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]\n\n# --- Squeeze-and-Excitation Block ---\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=8):\n        super(SEBlock, self).__init__()\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(),\n            nn.Linear(channels // reduction, channels, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        w = self.pool(x).view(b, c)\n        w = self.fc(w).view(b, c, 1, 1)\n        return x * w\n\n# --- EEGNet + Transformer ---\nclass EEGNetV4Transformer(nn.Module):\n    def __init__(self, num_classes, channels=8, samples=2250, transformer_dim=32, num_heads=4, num_layers=1):\n        super(EEGNetV4Transformer, self).__init__()\n\n        self.firstconv = nn.Sequential(\n            nn.Conv2d(1, 16, (1, 32), padding=(0, 16), bias=False),\n            nn.BatchNorm2d(16)\n        )\n\n        self.depthwiseConv = nn.Sequential(\n            nn.Conv2d(16, 32, (channels, 1), groups=16, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ELU(),\n            nn.AvgPool2d((1, 4)),\n            nn.Dropout(0.5)\n        )\n\n        self.separableConv = nn.Sequential(\n            nn.Conv2d(32, 32, (1, 16), padding=(0, 8), bias=False),\n            nn.BatchNorm2d(32),\n            nn.ELU(),\n            nn.AvgPool2d((1, 8)),\n            nn.Dropout(0.5)\n        )\n\n        self.attention = SEBlock(32)\n\n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(d_model=transformer_dim, nhead=num_heads, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.pos_encoder = PositionalEncoding(dim=transformer_dim)\n\n        self.classify = nn.Sequential(\n    nn.Linear(transformer_dim, 64),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(64, num_classes)\n)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # [B, 1, C, T]\n        x = self.firstconv(x)\n        x = self.depthwiseConv(x)\n        x = self.separableConv(x)\n        x = self.attention(x)\n\n        # x shape: [B, 32, 1, T'] → squeeze → [B, 32, T']\n        x = x.squeeze(2)  # [B, 32, T']\n        x = x.permute(0, 2, 1)  # [B, T', 32]\n\n        x = self.pos_encoder(x)\n        x = self.transformer(x)  # [B, T', 32]\n\n        # Global average pooling across T'\n        x = x.mean(dim=1)  # [B, 32]\n\n        return self.classify(x)\n","metadata":{"_uuid":"89f0167a-6aa7-4d76-ab9c-4c0dd9c6cdcf","_cell_guid":"65ebb00e-5629-4ce6-952d-ef0a052a0fe0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:38.520559Z","iopub.execute_input":"2025-06-30T17:14:38.520776Z","iopub.status.idle":"2025-06-30T17:14:38.538483Z","shell.execute_reply.started":"2025-06-30T17:14:38.520758Z","shell.execute_reply":"2025-06-30T17:14:38.537842Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, criterion,device, alpha=0.4):\n    model.train()\n    running_loss = 0.0\n    all_preds, all_labels = [], []\n\n    for X, y in tqdm(dataloader, desc='Training'):\n        X, y = X.to(device), y.to(device)\n        \n        # Apply mixup\n        mixed_X, y_a, y_b, lam = mixup_data(X, y, alpha)\n        optimizer.zero_grad()\n        outputs = model(mixed_X)\n\n        # Mixup loss\n        loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # For metrics: use clean inputs (no mixup) just for logging\n        with torch.no_grad():\n            preds_clean = torch.argmax(model(X), dim=1)\n            all_preds.append(preds_clean.cpu().numpy())\n            all_labels.append(y.cpu().numpy())\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n\n    return running_loss / len(dataloader), acc, f1\n\n\ndef validate(model, dataloader, criterion,device):\n    model.eval()\n    val_loss = 0\n    preds, targets = [], []\n    with torch.no_grad():\n        for X, y in tqdm(dataloader, desc='Validation'):\n            X, y = X.to(device), y.to(device)\n            out = model(X)\n            loss = criterion(out, y)\n            val_loss += loss.item()\n            preds.extend(out.argmax(1).cpu().numpy())\n            targets.extend(y.cpu().numpy())\n    acc = accuracy_score(targets, preds)\n    f1 = f1_score(targets, preds, average='macro')\n    return val_loss / len(dataloader), acc, f1\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, smoothing=0.1):\n        super().__init__()\n        self.smoothing = smoothing\n\n    def forward(self, pred, target):\n        n_class = pred.size(1)\n        log_preds = F.log_softmax(pred, dim=1)\n        with torch.no_grad():\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (n_class - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)\n        return torch.mean(torch.sum(-true_dist * log_preds, dim=1))","metadata":{"_uuid":"e3c539b3-fd27-48a8-b57e-4437fd7480ab","_cell_guid":"f628ce70-63ac-44bd-8535-b5e6a8b00d9c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:38.539113Z","iopub.execute_input":"2025-06-30T17:14:38.539356Z","iopub.status.idle":"2025-06-30T17:14:38.560532Z","shell.execute_reply.started":"2025-06-30T17:14:38.539337Z","shell.execute_reply":"2025-06-30T17:14:38.559753Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"base_path = '/kaggle/input/mtcaic3'\ntrain_ds = EEGDataset(task='MI', split='train', base_path=base_path)\nval_ds = EEGDataset(task='MI', split='validation', base_path=base_path)\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=16)\nif torch.cuda.is_available():\n    print(\"GPU\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = EEGNetV4Transformer(num_classes=2, samples=2250).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\ncriterion = LabelSmoothingCrossEntropy(smoothing=0.1)","metadata":{"_uuid":"2c24ba0a-dff2-4311-b861-a4f9385c0520","_cell_guid":"ff9fe158-e895-4df2-b7a2-48f58a76a4aa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:38.561510Z","iopub.execute_input":"2025-06-30T17:14:38.561746Z","iopub.status.idle":"2025-06-30T17:14:41.110630Z","shell.execute_reply.started":"2025-06-30T17:14:38.561731Z","shell.execute_reply":"2025-06-30T17:14:41.109916Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"best_val_f1 = 0\nfor epoch in range(1, 31):\n    print(f\"\\nEpoch {epoch}\")\n    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion,device)\n    val_loss, val_acc, val_f1 = validate(model, val_loader, criterion,device)\n\n    print(f\"Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n    print(f\"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n\n    if val_f1 > best_val_f1:\n        best_val_f1 = val_f1\n        torch.save(model.state_dict(), 'best_eegnet_model.pt')\n        print(\"Best model updated.\")","metadata":{"_uuid":"b3506d68-5dd9-4a4e-8d87-a6c82d106b14","_cell_guid":"517b7e83-2c43-42f8-977e-180606b36b52","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-30T17:14:41.111321Z","iopub.execute_input":"2025-06-30T17:14:41.111645Z","iopub.status.idle":"2025-06-30T18:24:14.884324Z","shell.execute_reply.started":"2025-06-30T17:14:41.111628Z","shell.execute_reply":"2025-06-30T18:24:14.883583Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:37<00:00,  1.05s/it]\nValidation: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5250 | Train F1: 0.5225\nVal Acc: 0.4400 | Val F1: 0.3056\nBest model updated.\n\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:17<00:00,  1.09it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.4942 | Train F1: 0.4941\nVal Acc: 0.5000 | Val F1: 0.4746\nBest model updated.\n\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5050 | Train F1: 0.4983\nVal Acc: 0.5600 | Val F1: 0.5536\nBest model updated.\n\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5300 | Train F1: 0.5293\nVal Acc: 0.5800 | Val F1: 0.4900\n\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.09it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5217 | Train F1: 0.5167\nVal Acc: 0.5000 | Val F1: 0.4505\n\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:17<00:00,  1.09it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5496 | Train F1: 0.5425\nVal Acc: 0.6200 | Val F1: 0.6073\nBest model updated.\n\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5583 | Train F1: 0.5542\nVal Acc: 0.5800 | Val F1: 0.5385\n\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5587 | Train F1: 0.5587\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 9\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5708 | Train F1: 0.5667\nVal Acc: 0.5200 | Val F1: 0.5000\n\nEpoch 10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5837 | Train F1: 0.5788\nVal Acc: 0.5400 | Val F1: 0.5398\n\nEpoch 11\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5883 | Train F1: 0.5878\nVal Acc: 0.5200 | Val F1: 0.5000\n\nEpoch 12\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5992 | Train F1: 0.5970\nVal Acc: 0.5400 | Val F1: 0.5398\n\nEpoch 13\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6021 | Train F1: 0.6003\nVal Acc: 0.5200 | Val F1: 0.5130\n\nEpoch 14\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6046 | Train F1: 0.6034\nVal Acc: 0.5600 | Val F1: 0.5572\n\nEpoch 15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6058 | Train F1: 0.6058\nVal Acc: 0.5600 | Val F1: 0.5226\n\nEpoch 16\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5942 | Train F1: 0.5935\nVal Acc: 0.5400 | Val F1: 0.5246\n\nEpoch 17\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:17<00:00,  1.09it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6042 | Train F1: 0.6033\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 18\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:20<00:00,  1.07it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5979 | Train F1: 0.5959\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 19\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6092 | Train F1: 0.6060\nVal Acc: 0.6000 | Val F1: 0.5660\n\nEpoch 20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6108 | Train F1: 0.6095\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 21\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6108 | Train F1: 0.6105\nVal Acc: 0.6000 | Val F1: 0.5994\n\nEpoch 22\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6008 | Train F1: 0.6008\nVal Acc: 0.6000 | Val F1: 0.5238\n\nEpoch 23\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6138 | Train F1: 0.6136\nVal Acc: 0.5600 | Val F1: 0.5536\n\nEpoch 24\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6162 | Train F1: 0.6136\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 25\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6100 | Train F1: 0.6081\nVal Acc: 0.6400 | Val F1: 0.6250\nBest model updated.\n\nEpoch 26\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6104 | Train F1: 0.6100\nVal Acc: 0.6000 | Val F1: 0.5974\n\nEpoch 27\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6258 | Train F1: 0.6247\nVal Acc: 0.5600 | Val F1: 0.5572\n\nEpoch 28\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6233 | Train F1: 0.6212\nVal Acc: 0.6200 | Val F1: 0.5559\n\nEpoch 29\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5925 | Train F1: 0.5911\nVal Acc: 0.6000 | Val F1: 0.5040\n\nEpoch 30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6225 | Train F1: 0.6222\nVal Acc: 0.6000 | Val F1: 0.5974\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for epoch in range(1, 31):\n    print(f\"\\nEpoch {epoch}\")\n    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion,device)\n    val_loss, val_acc, val_f1 = validate(model, val_loader, criterion,device)\n\n    print(f\"Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n    print(f\"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n\n    if val_f1 > best_val_f1:\n        best_val_f1 = val_f1\n        torch.save(model.state_dict(), 'best_eegnet_model.pt')\n        print(\"Best model updated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:24:14.885101Z","iopub.execute_input":"2025-06-30T18:24:14.885348Z","iopub.status.idle":"2025-06-30T19:32:54.158154Z","shell.execute_reply.started":"2025-06-30T18:24:14.885329Z","shell.execute_reply":"2025-06-30T19:32:54.157578Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:16<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6217 | Train F1: 0.6204\nVal Acc: 0.5800 | Val F1: 0.5785\n\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6254 | Train F1: 0.6246\nVal Acc: 0.6400 | Val F1: 0.6305\nBest model updated.\n\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6142 | Train F1: 0.6142\nVal Acc: 0.5800 | Val F1: 0.5716\n\nEpoch 4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6342 | Train F1: 0.6339\nVal Acc: 0.6400 | Val F1: 0.6250\n\nEpoch 5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6271 | Train F1: 0.6271\nVal Acc: 0.5800 | Val F1: 0.5716\n\nEpoch 6\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6254 | Train F1: 0.6254\nVal Acc: 0.5600 | Val F1: 0.5572\n\nEpoch 7\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6338 | Train F1: 0.6337\nVal Acc: 0.6800 | Val F1: 0.6528\nBest model updated.\n\nEpoch 8\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6212 | Train F1: 0.6208\nVal Acc: 0.6200 | Val F1: 0.6198\n\nEpoch 9\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6362 | Train F1: 0.6362\nVal Acc: 0.6400 | Val F1: 0.6180\n\nEpoch 10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6329 | Train F1: 0.6329\nVal Acc: 0.6200 | Val F1: 0.5924\n\nEpoch 11\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6329 | Train F1: 0.6322\nVal Acc: 0.6200 | Val F1: 0.6073\n\nEpoch 12\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6354 | Train F1: 0.6353\nVal Acc: 0.6200 | Val F1: 0.6073\n\nEpoch 13\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.13it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6300 | Train F1: 0.6295\nVal Acc: 0.6800 | Val F1: 0.6604\nBest model updated.\n\nEpoch 14\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6446 | Train F1: 0.6446\nVal Acc: 0.6400 | Val F1: 0.6347\n\nEpoch 15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6275 | Train F1: 0.6266\nVal Acc: 0.6400 | Val F1: 0.6180\n\nEpoch 16\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6371 | Train F1: 0.6367\nVal Acc: 0.5800 | Val F1: 0.5798\n\nEpoch 17\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6296 | Train F1: 0.6280\nVal Acc: 0.6200 | Val F1: 0.5386\n\nEpoch 18\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6346 | Train F1: 0.6346\nVal Acc: 0.6600 | Val F1: 0.6566\n\nEpoch 19\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6371 | Train F1: 0.6368\nVal Acc: 0.6000 | Val F1: 0.5895\n\nEpoch 20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.10it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6412 | Train F1: 0.6409\nVal Acc: 0.6000 | Val F1: 0.5040\n\nEpoch 21\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6346 | Train F1: 0.6345\nVal Acc: 0.6400 | Val F1: 0.6250\n\nEpoch 22\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6417 | Train F1: 0.6416\nVal Acc: 0.6000 | Val F1: 0.5895\n\nEpoch 23\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6512 | Train F1: 0.6512\nVal Acc: 0.6200 | Val F1: 0.6124\n\nEpoch 24\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6375 | Train F1: 0.6371\nVal Acc: 0.6200 | Val F1: 0.5924\n\nEpoch 25\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6475 | Train F1: 0.6473\nVal Acc: 0.6400 | Val F1: 0.6305\n\nEpoch 26\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6438 | Train F1: 0.6437\nVal Acc: 0.6600 | Val F1: 0.6264\n\nEpoch 27\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6462 | Train F1: 0.6462\nVal Acc: 0.6600 | Val F1: 0.6427\n\nEpoch 28\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:26<00:00,  1.02it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6362 | Train F1: 0.6357\nVal Acc: 0.6000 | Val F1: 0.5974\n\nEpoch 29\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:14<00:00,  1.12it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6508 | Train F1: 0.6508\nVal Acc: 0.6000 | Val F1: 0.4802\n\nEpoch 30\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [02:15<00:00,  1.11it/s]\nValidation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6462 | Train F1: 0.6460\nVal Acc: 0.5400 | Val F1: 0.5383\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"best_val_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:35:03.880005Z","iopub.execute_input":"2025-06-30T19:35:03.880272Z","iopub.status.idle":"2025-06-30T19:35:03.884986Z","shell.execute_reply.started":"2025-06-30T19:35:03.880256Z","shell.execute_reply":"2025-06-30T19:35:03.884183Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.6604414261460102"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Swish activation\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n# CBAM Block (Channel & Spatial Attention)\nclass CBAM(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(CBAM, self).__init__()\n        self.channel_att = SEBlock(channel, reduction)\n        self.spatial_att = nn.Sequential(\n            nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x_out = self.channel_att(x)\n        avg_out = torch.mean(x_out, dim=1, keepdim=True)\n        max_out, _ = torch.max(x_out, dim=1, keepdim=True)\n        concat = torch.cat([avg_out, max_out], dim=1)\n        scale = self.spatial_att(concat)\n        return x_out * scale\n\n# Same SEBlock, configurable reduction\nclass SEBlock(nn.Module):\n    def __init__(self, channel, reduction=4):\n        super(SEBlock, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n# Tiny Transformer Encoder for temporal modeling\nclass TemporalTransformer(nn.Module):\n    def __init__(self, dim, heads=2, layers=1):\n        super(TemporalTransformer, self).__init__()\n        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n\n    def forward(self, x):\n        # x: [B, C, 1, T] -> flatten spatial dims -> [B, T, C]\n        b, c, _, t = x.size()\n        x = x.squeeze(2).permute(0, 2, 1)\n        x = self.transformer(x)\n        # [B, T, C] -> [B, C, 1, T]\n        x = x.permute(0, 2, 1).unsqueeze(2)\n        return x\n\nclass EEGNetPro(nn.Module):\n    def __init__(self, num_classes, channels=8, samples=2250):\n        super(EEGNetPro, self).__init__()\n        self.swish = Swish()\n\n        self.firstconv = nn.Sequential(\n            nn.Conv2d(1, 16, (1, 32), padding=(0, 32), bias=False),\n            nn.BatchNorm2d(16)\n        )\n\n        self.depthwiseConv = nn.Sequential(\n            nn.Conv2d(16, 32, (channels, 1), groups=16, bias=False),\n            nn.BatchNorm2d(32),\n            self.swish,\n            nn.BatchNorm2d(32),\n            nn.AvgPool2d((1, 4)),\n            nn.Dropout(0.5)\n        )\n        self.se_block1 = SEBlock(32, reduction=4)\n\n        self.separableConv = nn.Sequential(\n            nn.Conv2d(32, 32, (1, 16), padding=(0, 8), bias=False),\n            nn.BatchNorm2d(32),\n            self.swish,\n            nn.BatchNorm2d(32),\n            nn.AvgPool2d((1, 8)),\n            nn.Dropout(0.5)\n        )\n\n        self.cbam = CBAM(32)\n\n        self.temporal_transformer = TemporalTransformer(dim=32, heads=2, layers=1)\n\n        self.flatten_dim = self._get_flattened_size(channels, samples)\n        self.classify = nn.Linear(self.flatten_dim, num_classes)\n\n    def _get_flattened_size(self, channels, samples):\n        with torch.no_grad():\n            x = torch.zeros(1, 1, channels, samples)\n            x = self.firstconv(x)\n            x = self.depthwiseConv(x)\n            x = self.se_block1(x)\n            x = self.separableConv(x)\n            x = self.cbam(x)\n            x = self.temporal_transformer(x)\n            return x.reshape(1, -1).shape[1]\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.firstconv(x)\n        x = self.depthwiseConv(x)\n        x = self.se_block1(x)\n        x = self.separableConv(x)\n        x = self.cbam(x)\n        x = self.temporal_transformer(x)\n        x = x.reshape(x.size(0), -1)\n        return self.classify(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:35:16.321093Z","iopub.execute_input":"2025-06-30T19:35:16.321381Z","iopub.status.idle":"2025-06-30T19:35:16.334095Z","shell.execute_reply.started":"2025-06-30T19:35:16.321365Z","shell.execute_reply":"2025-06-30T19:35:16.333383Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model_mi = EEGNetV4Transformer(num_classes = 2, samples=2250).to(device)\nmodel_mi.attention = SEBlock(channel=32, reduction=8)  \nmodel_mi.load_state_dict(torch.load('/kaggle/working/best_eegnet_model.pt', map_location='cpu'))  # or 'cuda' if available\nmodel_mi.eval()\n\nmodel_ssvep = EEGNetPro(num_classes = 4, samples=1750).to(device)\nmodel_ssvep.load_state_dict(torch.load('/kaggle/input/best_ssvep/pytorch/default/1/best_ssvep_model.pt', map_location='cpu'))  # or 'cuda' if available\nmodel_ssvep.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:39:48.493720Z","iopub.execute_input":"2025-06-30T19:39:48.494093Z","iopub.status.idle":"2025-06-30T19:39:48.536667Z","shell.execute_reply.started":"2025-06-30T19:39:48.494074Z","shell.execute_reply":"2025-06-30T19:39:48.536088Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"EEGNetPro(\n  (swish): Swish()\n  (firstconv): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(1, 32), stride=(1, 1), padding=(0, 32), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (depthwiseConv): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(8, 1), stride=(1, 1), groups=16, bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Swish()\n    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n    (5): Dropout(p=0.5, inplace=False)\n  )\n  (se_block1): SEBlock(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (fc): Sequential(\n      (0): Linear(in_features=32, out_features=8, bias=False)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=8, out_features=32, bias=False)\n      (3): Sigmoid()\n    )\n  )\n  (separableConv): Sequential(\n    (0): Conv2d(32, 32, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Swish()\n    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n    (5): Dropout(p=0.5, inplace=False)\n  )\n  (cbam): CBAM(\n    (channel_att): SEBlock(\n      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n      (fc): Sequential(\n        (0): Linear(in_features=32, out_features=2, bias=False)\n        (1): ReLU(inplace=True)\n        (2): Linear(in_features=2, out_features=32, bias=False)\n        (3): Sigmoid()\n      )\n    )\n    (spatial_att): Sequential(\n      (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n      (1): Sigmoid()\n    )\n  )\n  (temporal_transformer): TemporalTransformer(\n    (transformer): TransformerEncoder(\n      (layers): ModuleList(\n        (0): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n          )\n          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (classify): Linear(in_features=1760, out_features=4, bias=True)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport pandas as pd\n\ndef test_and_generate_csv(model, dataset_class, task, base_path, output_csv='submission.csv', batch_size=32):\n    # Load test set\n    test_dataset = dataset_class(task=task, split='test', base_path=base_path, apply_noise=False)\n    \n    # Load train set just to fit label encoder\n    train_dataset = dataset_class(task=task, split='train', base_path=base_path, apply_noise=False)\n    test_dataset.label_encoder = train_dataset.label_encoder  # assign fitted encoder\n\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    model.eval()\n    model.to('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    all_preds = []\n    all_ids = []\n\n    with torch.no_grad():\n        for X in tqdm(test_loader, desc=f'Testing [{task}]'):\n            X = X.to('cuda' if torch.cuda.is_available() else 'cpu')\n            outputs = model(X)\n            preds = outputs.argmax(dim=1).cpu().numpy()\n            all_preds.extend(preds)\n\n    # Get the test metadata CSV\n    test_meta = pd.read_csv(f'{base_path}/test.csv')\n    test_meta = test_meta[test_meta['task'] == task].reset_index(drop=True)\n\n    # Decode numeric predictions to labels\n    if hasattr(test_dataset, 'label_encoder') and hasattr(test_dataset.label_encoder, 'inverse_transform'):\n        all_preds = test_dataset.label_encoder.inverse_transform(all_preds)\n\n    output_df = pd.DataFrame({\n        'id': test_meta['id'],\n        'label': all_preds\n    })\n    output_df.to_csv(output_csv, index=False)\n    print(f\" Saved predictions to {output_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:40:14.128826Z","iopub.execute_input":"2025-06-30T19:40:14.129057Z","iopub.status.idle":"2025-06-30T19:40:14.136070Z","shell.execute_reply.started":"2025-06-30T19:40:14.129040Z","shell.execute_reply":"2025-06-30T19:40:14.135285Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"test_and_generate_csv(model_mi, EEGDataset, task='MI', base_path='/kaggle/input/mtcaic3', output_csv='submission_mi.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:40:28.910105Z","iopub.execute_input":"2025-06-30T19:40:28.910444Z","iopub.status.idle":"2025-06-30T19:40:32.015200Z","shell.execute_reply.started":"2025-06-30T19:40:28.910427Z","shell.execute_reply":"2025-06-30T19:40:32.014460Z"}},"outputs":[{"name":"stderr","text":"Testing [MI]: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]","output_type":"stream"},{"name":"stdout","text":" Saved predictions to submission_mi.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"test_and_generate_csv(model_ssvep, EEGDataset, task='SSVEP', base_path='/kaggle/input/mtcaic3', output_csv='submission_ssvep.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T19:40:45.056359Z","iopub.execute_input":"2025-06-30T19:40:45.056611Z","iopub.status.idle":"2025-06-30T19:40:47.314680Z","shell.execute_reply.started":"2025-06-30T19:40:45.056593Z","shell.execute_reply":"2025-06-30T19:40:47.314100Z"}},"outputs":[{"name":"stderr","text":"Testing [SSVEP]: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":" Saved predictions to submission_ssvep.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}